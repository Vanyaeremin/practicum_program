# Runner Service (Порт: 8002)

## Обзор

**Runner Service** — сервис предобработки видео в микросервисной архитектуре детекции объектов. Сервис отвечает за извлечение кадров из видео, их предобработку и отправку в inference сервис для детекции объектов.

## Архитектура обработки

Сервис работает по принципу обработки видео покадерно с использованием отдельной базы данных:

1. **Читает события** из Kafka темы `outbox_events`
2. **Скачивает видео** из MinIO по пути `input/{video_id}.mp4`
3. **Извлекает кадры** (каждый 5-й кадр) с помощью OpenCV
4. **Предобрабатывает** каждый кадр отдельно:
   - Gaussian blur (ksize=3)
   - Корректировка контраста/яркости (alpha=1.3, beta=5)
5. **Сохраняет кадры** в S3 бакет "frames" по пути `frames/{event_id}/{frame_id}.jpg`
6. **Отправляет задачи** в inference через Kafka тему `inference_tasks` (с путями к кадрам в S3)
6. **Получает результаты** из Kafka темы `inference_results`
7. **Сохраняет результаты** в отдельную БД `runner_db.runner_predictions`
8. **Объединяет кадры** в финальный JSON при получении всех результатов
9. **Устанавливает статус** `predictable` в runner_db 

## Внутренние компоненты

### Kafka Consumers

#### 1. Consumer для предобработки видео
- **Тема**: `outbox_events`
- **Группа**: `runner-group`
- **Функция**: Извлечение и отправка кадров в inference

#### 2. Consumer для сборки результатов
- **Тема**: `inference_results`
- **Группа**: `runner-results-group`
- **Функция**: Сбор результатов детекции по кадрам

### Очерёдность кадров

Очерёдность кадров обеспечивается несколькими механизмами:

1. **Kafka Consumer Groups**: Все кадры одного видео обрабатываются в рамках одного consumer group, что гарантирует последовательную обработку
2. **Последовательная отправка**: Кадры отправляются в Kafka последовательно в цикле
3. **frame_id**: Каждое сообщение содержит `frame_id` (номер кадра: 0, 5, 10, 15, ...)
4. **Сортировка при объединении**: Кадры сортируются по `frame_id` перед объединением в финальный JSON

## Технические детали

### Асинхронность и избегание блокировки Event Loop

Сервис активно использует асинхронность для обеспечения высокой производительности и отзывчивости:

#### 1. Асинхронные клиенты Kafka (aiokafka)

**Проблема**: Синхронный клиент Kafka блокирует event loop при отправке/получении сообщений.

**Решение**: Использование `aiokafka` — полностью асинхронного клиента.

#### 2. run_in_executor для I/O-блокирующих операций

**Проблема**: Синхронные операции с MongoDB и MinIO блокируют event loop.

**Решение**: Использование `run_in_executor` для вынесения блокирующих операций в отдельный поток.

**Как это работает**:
- `run_in_executor(None, func)` использует `ThreadPoolExecutor` по умолчанию
- Функция выполняется в отдельном потоке
- Event loop продолжает обрабатывать другие задачи
- Когда функция завершается, результат возвращается через await

### Борьба с GIL (Global Interpreter Lock)

**GIL (Global Interpreter Lock)** — это механизм в CPython, который предотвращает одновременное выполнение байт-кода несколькими потоками в одном процессе. Это блокирует истинный параллелизм для CPU-интенсивных задач.

**Проблема в Runner Service**:
- Извлечение кадров из видео — CPU-интенсивная операция
- Предобработка изображений (Gaussian blur, корректировка контраста) — CPU-интенсивная операция
- Если выполнять эти операции в основном потоке, GIL блокирует выполнение других задач

**Решение**:
1. **ProcessPoolExecutor** для CPU-интенсивных задач:
   - Каждый процесс имеет свой GIL
   - Истинный параллелизм на многоядерных CPU
   - Event loop не блокируется

2. **ThreadPoolExecutor** (через `run_in_executor(None, ...)`) для I/O операций:
   - MongoDB операции
   - MinIO операции
   - Event loop не блокируется

## Управление статусами

### В runner_db.runner_predictions (внутренние статусы):
- `processing` — идёт обработка кадров
- `predictable` — все кадры обработаны, результат готов для сохранения в S3 через outbox_s3
- `ready` — результат сохранён в S3 (обновляется outbox_s3 worker)

## Отказоустойчивость и проверка доступности сервисов

### Проверка доступности Kafka
### Проверка доступности MinIO/S3
### Проверка доступности MongoDB

## Логирование

Детальное логирование всех операций:
- Подключение к Kafka
- Скачивание файлов из MinIO
- Извлечение и отправка кадров
- Получение и обработка результатов
- Ошибки и исключения

## Идемпотентность

**Идемпотентные операции**:
- **Проверка статусов**: Проверка статусов перед обработкой
- **Условное обновление**: Обновление статусов только при совпадении условий
- **Уникальные event_id**: Каждое видео имеет уникальный ID

**Реализация идемпотентности**:
- **MongoDB атомарность**: Атомарные операции обновления статусов
- **Kafka коммиты**: Коммит только после успешной обработки
- **Проверка состояния**: Проверка статусов перед началом обработки