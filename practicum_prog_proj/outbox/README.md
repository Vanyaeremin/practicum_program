# Outbox Worker Service

## Обзор

**Outbox Worker** — реализация паттерна Transactional Outbox для надёжной публикации событий в Kafka. Сервис обеспечивает гарантированную доставку событий из MongoDB в Kafka, предотвращая потерю данных при временных недоступностях сервисов.

## Основные функции

1. **Опрос MongoDB outbox** на события со статусом `"new"`
2. **Публикация событий** в Kafka тему `outbox_events`
3. **Обновление статуса** на `"sent"` после успешной отправки
4. **Обработка ошибок** и повторные попытки отправки

## Паттерн Transactional Outbox — подробное объяснение

### Что такое Transactional Outbox

**Transactional Outbox** — это паттерн проектирования для обеспечения надёжной доставки событий в распределённых системах. 

**Принцип работы**:
1. **Асинхронная публикация**: Outbox worker забирает события и публикует в Kafka
2. **Гарантия доставки**: Событие не меняет статус до успешной отправки в Kafka
3. **Отказоустойчивость**: При сбоях Kafka событие остаётся в том же статусе и будет обработано позже

### Преимущества паттерна

- **Надёжность**: События не теряются при сбоях Kafka или сети
- **Отказоустойчивость**: Автоматические повторные попытки при временных сбоях
- **Идемпотентность**: Повторная обработка безопасна (статус обновляется только после успеха)
- **Мониторинг**: Все события отслеживаются в БД, можно видеть статусы обработки

### Жизненный цикл события в Outbox

1. **Создание**: API Service создаёт событие в outbox со статусом `"new"` 
2. **Отправка**: Outbox Worker находит событие со статусом `"new"` и отправляет в Kafka
3. **Подтверждение**: После успешной отправки статус обновляется на `"sent"`
4. **Обработка**: Runner Service получает событие из Kafka и обрабатывает

## Архитектура

### Поток данных
```
api_checkout → MongoDB outbox → Outbox Worker → Kafka → Runner Service
```

### Статусы событий
- `new` — Событие создано, ожидает отправки
- `sent` — Событие успешно отправлено в Kafka

## Технические детали


### Настройки Kafka Producer
```python
producer = AIOKafkaProducer(
                bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                value_serializer=lambda v: json.dumps(v).encode("utf-8"),
                key_serializer=lambda k: k.encode("utf-8") if k else None,
                # Идемпотентность на уровне producer (Автоматическая дедупликация при сетевых сбоях и повторных отправках)
                enable_idempotence=True,
                acks='all',  # Ждём подтверждения от всех реплик (ждём сохранение на всех брокерах)
            )
```

**Зачем нужен идемпотентный producer?**

Идемпотентный producer решает критическую проблему атомарности между отправкой в Kafka и обновлением статуса в MongoDB:

**Проблема без идемпотентности:**
- Если `producer.send()` успешен, но `update_one()` упадёт (сеть, MongoDB недоступен)
- При следующей итерации событие отправится повторно → дубликат в Kafka

**Решение с идемпотентностью:**
- Kafka присваивает producer ID (PID) и sequence number каждому сообщению
- При повторной отправке брокер распознаёт дубликат по PID + sequence number и отклоняет его
- Сообщение не дублируется, даже если `update_one()` упадёт

**Message Key:**
- Используется `event_id` как ключ сообщения
- Гарантирует, что все сообщения с одним `event_id` попадут в одну partition
- Обеспечивает порядок обработки событий


## Отказоустойчивость и проверка доступности сервисов

### Проверка доступности Kafka

Worker проверяет доступность Kafka при старте и автоматически восстанавливается при сбоях.

**Преимущества**:
- **Автоматическое восстановление**: При восстановлении Kafka worker автоматически подключается
- **Не блокирует старт**: Worker запускается и ждёт доступности Kafka
- **Логирование**: Все ошибки подключения логируются

### Проверка доступности MongoDB

Worker обрабатывает ошибки MongoDB с логированием и продолжением работы.