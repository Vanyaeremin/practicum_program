# Microservices Video Detection System

## Обзор проекта

**Microservices Video Detection System** — распределённая система детекции объектов на видео с использованием YOLO модели. Система построена по микросервисной архитектуре с использованием паттерна Transactional Outbox для обеспечения надёжности и отказоустойчивости.

### Основные возможности

- **Детекция объектов** на видео с использованием YOLO модели
- **Обработка по кадрам** для оптимизации производительности
- **Надёжность** с использованием паттерна Transactional Outbox
- **Асинхронная обработка** для высокой производительности
- **REST API** для загрузки видео и получения результатов

## Архитектура системы


## API Эндпоинты

### API Checkout Service (Порт: 8080)

#### Health Check
- `GET /api/`, `GET /api` — Health check
- `GET /api/health` — Health check

#### Основные операции
- `POST /api/upload_video` — Загрузка видео для обработки
- `POST /api/request` — Создание outbox события
- `GET /api/status/all` — Получение статусов всех операций
- `GET /api/result_video/{event_id}` — Получение результата обработки видео
- `DELETE /api/cleanup/all` — Полная очистка системы

### Runner Service (Порт: 8002)
- `GET /health` — Health check сервиса

### Inference Service (Порт: 8003)
- `GET /data`, `GET /api/data` — Базовый эндпоинт сервиса
- `GET /health` — Health check (если определён)

## Подробное описание пути видео

### Этап 1: Загрузка видео
```
Клиент → POST /upload_video → API Checkout Service
```

1. **Приём файла**: Клиент отправляет видеофайл через POST запрос
2. **Генерация ID**: Создаётся уникальный `video_id` (UUID4)
3. **Сохранение в MinIO**: Видео сохраняется по пути `input/{video_id}.mp4`
4. **Создание события**: В MongoDB outbox создаётся запись:
   ```json
   {
     "_id": "video-uuid",
     "status": "new",
     "payload": {
       "bucket": "videos",
       "object": "input/video-uuid.mp4",
       "media_type": "video"
     },
     "created_at": "2024-01-01T12:00:00Z"
   }
   ```
5. **Статус**: `new` — Новое событие создано

### Этап 2: Отправка в очередь обработки
```
MongoDB outbox → Outbox Worker → Kafka (outbox_events)
```

1. **Опрос**: Outbox Worker находит события со статусом `new`
2. **Публикация**: Событие отправляется в Kafka тему `outbox_events`
3. **Обновление статуса**: `new` → `sent`
4. **Статус**: `sent` — Событие отправлено в очередь обработки

### Этап 3: Предобработка видео
```
Kafka (outbox_events) → Runner Service → MinIO → Kafka (inference_tasks)
```

1. **Получение задачи**: Runner Service получает сообщение из Kafka
2. **Скачивание видео**: Файл скачивается из MinIO (`input/{video_id}.mp4`)
3. **Извлечение кадров**: Каждый 5-й кадр извлекается и предобрабатывается:
   - Gaussian blur (ksize=3)
   - Корректировка контраста (alpha=1.3, beta=5)
4. **Инициализация трекинга**: Создаётся запись в `runner_db.runner_predictions`:
   ```json
   {
     "_id": "video-uuid",
     "total_frames": 30,
     "received_frames": 0,
     "frame_results": {},
     "status": "processing"
   }
   ```
5. **Отправка кадров**: Каждый кадр отправляется в Kafka тему `inference_tasks`
6. **Инициализация трекинга**: Создаётся запись в `runner_db.runner_predictions` со статусом `processing`
7. **Статус**: `processing` (runner_db) — Видео обрабатывается в runner (внутренний статус, не видимый через API)

### Этап 4: Детекция объектов
```
Kafka (inference_tasks) → Inference Service → YOLO → Kafka (inference_results)
```

1. **Получение кадра**: Inference Service получает кадр (base64 JPEG)
2. **Декодирование**: Base64 → JPEG → numpy array
3. **Детекция YOLO**:
   - Модель: `best.pt`
   - Порог уверенности: 0.25
   - Порог IoU: 0.45
4. **Форматирование результата**:
   ```json
   {
     "frame": 0,
     "objects": [
       {"class": "cat", "box": [100, 200, 300, 400], "conf": 0.87}
     ]
   }
   ```
5. **Отправка результата**: В Kafka тему `inference_results`
6. **Статус**: Кадры обрабатываются в inference

### Этап 5: Сбор результатов
```
Kafka (inference_results) → Runner Service → MongoDB runner_db.runner_predictions
```

1. **Получение результатов**: Runner Service получает результаты по кадрам
2. **Сохранение кадров**: Результаты сохраняются в `runner_db.runner_predictions`:
   ```json
   {
     "frame_results": {
       "0": {"frame": 0, "objects": [...]},
       "5": {"frame": 5, "objects": [...]}
     },
     "received_frames": 30
   }
   ```
3. **Проверка завершения**: Когда `received_frames >= total_frames`
4. **Объединение результатов**: Сортировка по frame_id и объединение:
   ```json
   {
     "prediction": [
       {"frame": 0, "objects": [...]},
       {"frame": 5, "objects": [...]}
     ],
     "status": "predictable"
   }
   ```
5. **Обновление статуса**: 
   - В runner_db: `processing` → `predictable`
   - Outbox НЕ обновляется (соответствует принципам микросервисов)
6. **Статус**: `predictable` (runner_db) — Детекция завершена, результат готов к сохранению в S3

### Этап 6: Сохранение в S3
```
MongoDB runner_db → Outbox S3 Worker → MinIO (detection/)
```

1. **Опрос**: Outbox S3 Worker находит записи напрямую в `runner_db.runner_predictions` со статусом `predictable`
2. **Чтение данных**: Из записи в runner_db берутся `event_id`, `bucket` и `prediction` (финальный JSON)
3. **Сохранение в MinIO**: JSON сохраняется по пути `detection/{video_id}.json`
4. **Обновление runner_db**:
   ```json
   {
     "status": "ready",
     "ready_at": "2024-01-01T12:05:00Z",
     "output_s3": {
       "bucket": "videos",
       "object": "detection/video-uuid.json"
     }
   }
   ```
5. **Сохранение в runner_db**: Данные остаются в `runner_db.runner_predictions` (не удаляются)
6. **Статус**: `ready` (runner_db) — Результат сохранён в S3 и готов к забору

### Этап 7: Получение результата
```
Клиент → GET /result_video/{event_id} → API Checkout → MinIO → Клиент
```

1. **Запрос результата**: Клиент запрашивает результат по `video_id`
2. **Проверка наличия JSON**: API проверяет наличие файла `detection/{video_id}.json` в S3
3. **Если файл есть**: JSON загружается из S3 и возвращается клиенту (статус "ready")
4. **Если файла нет**: Возвращается статус из outbox ("new" или "sent")

## Система статусов

API использует упрощённый подход для определения статусов - проверяет наличие JSON файла в S3:

#### Статусы, видимые клиенту через API
1. **`new`** — Новое событие создано, ожидает отправки в очередь (из outbox)
2. **`sent`** — Событие отправлено в очередь обработки (из outbox)
3. **`ready`** — Результат сохранён в S3 и готов к забору (определяется наличием JSON файла в S3)

#### Логика определения статуса
- **API НЕ обращается к runner_db**
- **API проверяет наличие JSON файла** в S3 по пути `detection/{event_id}.json`
- **Если файл есть в S3** → статус `"ready"` (готов к забору)
- **Если файла нет в S3** → статус из outbox (`"new"` или `"sent"`)

#### Внутренние статусы (не видимые через API)
Внутри системы используются дополнительные статусы в runner_db:
- **`processing`** — Видео обрабатывается: кадры извлекаются и отправляются в inference
- **`predictable`** — Детекция завершена, все кадры обработаны, результат готов к сохранению в S3
- **`ready`** — Результат сохранён в S3 (используется только внутри runner_db)

### Полный жизненный цикл
1. **`new`** (outbox) — Новое событие создано
2. **`sent`** (outbox) — Событие отправлено в Kafka
3. **`processing`** (runner_db, внутренний) — Видео обрабатывается
4. **`predictable`** (runner_db, внутренний) — Результат готов к сохранению в S3
5. **`ready`** (определяется наличием JSON в S3) — Результат готов к забору

## Асинхронность и борьба с GIL

### Проблема GIL (Global Interpreter Lock) — подробное объяснение

**GIL (Global Interpreter Lock)** — это механизм в CPython (стандартной реализации Python), который предотвращает одновременное выполнение байт-кода несколькими потоками в одном процессе. GIL — это мьютекс (mutex), который блокирует выполнение Python-кода в других потоках, пока один поток выполняет байт-код.

#### Почему GIL существует?
- **Упрощение управления памятью**: GIL защищает внутренние структуры данных CPython от гонок данных (race conditions)
- **Интеграция с C-расширениями**: Многие библиотеки (NumPy, OpenCV) написаны на C и не потокобезопасны
- **Исторические причины**: CPython был создан до эры многоядерных процессоров

### Решения в проекте — детальное описание

#### 1. Асинхронный фреймворк FastAPI и избегание блокировки Event Loop

**Проблема**: FastAPI использует asyncio event loop для обработки запросов. Если выполнить синхронную блокирующую операцию (например, запрос к MongoDB) напрямую в async функции, весь event loop заблокируется, и сервис не сможет обрабатывать другие запросы.

#### 2. run_in_executor для I/O-блокирующих операций (MongoDB, MinIO)

**Проблема**: Синхронные клиенты MongoDB (pymongo) и MinIO блокируют event loop при выполнении операций.

**Как это работает**:
- `run_in_executor(None, func)` создаёт задачу в ThreadPoolExecutor
- Синхронная функция выполняется в отдельном потоке
- Event loop продолжает работать и обрабатывать другие задачи
- Когда функция завершается, результат возвращается через await

#### 3. ProcessPoolExecutor для CPU-интенсивных задач (обход GIL)

**Проблема**: CPU-интенсивные операции (обработка изображений, извлечение кадров из видео) блокируют GIL и event loop, даже если выполняются через `run_in_executor(None, ...)` в потоке.

**Решение**: Использование `ProcessPoolExecutor` вместо `ThreadPoolExecutor`. Процессы имеют отдельные GIL, что обеспечивает истинный параллелизм.

**Как это работает**:
- `ProcessPoolExecutor` создаёт отдельные процессы Python
- Каждый процесс имеет свой собственный GIL
- Несколько процессов могут выполнять CPU-интенсивный код одновременно на разных ядрах CPU
- Event loop не блокируется, так как выполнение происходит в отдельном процессе

**Преимущества ProcessPoolExecutor**:
- **Истинный параллелизм**: Используются все ядра CPU
- **Обход GIL**: Каждый процесс имеет свой GIL
- **Не блокирует event loop**: Выполнение в отдельном процессе
- **Масштабируемость**: Можно обрабатывать несколько видео одновременно

#### 4. Асинхронные клиенты Kafka (aiokafka) — избегание блокировки Event Loop

**Проблема**: Синхронный клиент Kafka (kafka-python) блокирует event loop при отправке/получении сообщений.

**Решение**: Использование `aiokafka` — полностью асинхронного клиента Kafka.

**Как это работает**:
- `aiokafka` использует asyncio для неблокирующих операций
- Все операции (подключение, отправка, получение) являются async/await
- Event loop не блокируется во время ожидания ответа от Kafka
- Можно обрабатывать множество сообщений одновременно

## Паттерн Transactional Outbox — подробное объяснение

### Что такое Transactional Outbox

**Transactional Outbox** — это паттерн проектирования для обеспечения надёжной доставки событий в распределённых системах. Паттерн решает критическую проблему **двойной записи (double-write)** в распределённых системах, когда нужно атомарно обновить базу данных и отправить событие в message queue.

### Проблема без Outbox (Double-Write Problem)

В распределённых системах часто возникает необходимость:
1. Сохранить данные в базу данных
2. Отправить событие в message queue (Kafka, RabbitMQ и т.д.)

Паттерн решает проблему, разделяя операции на два этапа:

```
Клиент → API Service → База данных (outbox таблица) [АТОМАРНАЯ ТРАНЗАКЦИЯ]
                          ↓
                    Outbox Worker → Message Queue (асинхронная отправка)
```

**Принцип работы**:
1. **Асинхронная отправка**: Отдельный worker (Outbox Worker) периодически опрашивает outbox и отправляет события в queue
2. **Гарантия доставки**: Событие остаётся в outbox до успешной отправки в queue
3. **Идемпотентность**: Повторная обработка безопасна (статус обновляется только после успешной отправки)

### Реализация в проекте

#### 1. Outbox Worker (MongoDB → Kafka)

**Назначение**: Обеспечивает надёжную доставку событий из MongoDB outbox в Kafka.

**Отказоустойчивость**:
- **Повторные попытки**: Kafka producer имеет `retries=5` для автоматических повторов
- **Сохранение состояния**: Событие остаётся в outbox со статусом "new" при ошибке
- **Автоматическое восстановление**: При следующей итерации событие будет обработано снова
- **Идемпотентность**: Повторная отправка безопасна (Kafka гарантирует доставку)

#### 2. Outbox S3 Worker (MongoDB → MinIO)

**Назначение**: Обеспечивает надёжное сохранение результатов детекции из MongoDB в MinIO (S3).

**Отказоустойчивость**:
- **Проверка доступности MinIO**: Ожидание готовности при старте
- **Сохранение состояния**: Запись остаётся со статусом "predictable" в runner_db при ошибке
- **Автоматическое восстановление**: При следующей итерации запись будет обработана снова
- **Микросервисная архитектура**: Данные читаются из runner_db, что обеспечивает изоляцию сервисов
- **Не обновляет outbox**: Outbox S3 Worker НЕ обновляет outbox - только runner_db

## Технологический стек

### Backend
- **Python 3.9+** — основной язык разработки
- **FastAPI** — асинхронный веб-фреймворк
- **aiokafka** — асинхронный клиент Kafka
- **pymongo** — клиент MongoDB
- **minio** — S3-совместимый клиент

### ML/AI
- **Ultralytics YOLO** — детекция объектов
- **OpenCV** — обработка изображений и видео
- **NumPy** — операции с массивами

### Инфраструктура
- **Kafka** — message queue для асинхронной обработки
- **MongoDB** — хранилище статусов и промежуточных результатов
  - **main_db** — основная БД для outbox событий
  - **runner_db** — отдельная БД для сервиса runner
- **MinIO** — S3-совместимое объектное хранилище
- **Docker** — контейнеризация сервисов

## Развертывание

### Docker Compose
```bash
docker-compose up -d
```

Сервисы:
- `api_checkout` — порт 8080
- `runner` — порт 8002
- `inference` — порт 8003
- `outbox_worker` — фоновый процесс
- `outbox_s3_worker` — фоновый процесс
- `kafka` — порт 9092
- `mongo` — порт 27017
- `minio` — порт 9000

### Переменные окружения
```bash
# Основные БД
MONGO_URI=mongodb://admin:password@mongo:27017/
RUNNER_MONGO_URI=mongodb://admin:password@mongo:27017/

# MinIO
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
```

## Примеры использования

### Загрузка и обработка видео
```bash
# 1. Загрузка видео
curl -X POST "http://localhost:8080/api/upload_video" \
  -F "file=@video.mp4" \
  -F "bucket=videos"

# Ответ: {"status": "ok", "event_id": "video-uuid"}

# 2. Проверка статуса
curl "http://localhost:8080/api/status/all"

# 3. Получение результата
curl "http://localhost:8080/api/result_video/video-uuid"
```

### Пример результата
```json
{
  "status": "ready",
  "event_id": "video-uuid",
  "prediction": [
    {
      "frame": 0,
      "objects": [
        {
          "class": "cat",
          "box": [100, 200, 300, 400],
          "conf": 0.87
        }
      ]
    }
  ]
}
```

## Мониторинг и отладка

### Логирование
Все сервисы используют детальное логирование с `flush=True`:
- Статусы обработки
- Ошибки и исключения
- Время выполнения операций
- Подключения к внешним сервисам

### Статусы обработки
```bash
# Получить все статусы
curl "http://localhost:8080/api/status/all"

# Ответ
{
  "operations": [
    {
      "video_id": "video-uuid",
      "status_code": "ready",
      "status_description": "Результат сохранён в S3 и готов к забору",
    }
  ],
  "total": 1
}
```