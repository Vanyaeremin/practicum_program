# Outbox Worker Service

## Обзор

**Outbox Worker** — реализация паттерна Transactional Outbox для надёжной публикации событий в Kafka. Сервис обеспечивает гарантированную доставку событий из MongoDB в Kafka, предотвращая потерю данных при временных недоступностях сервисов.

## Основные функции

1. **Опрос MongoDB outbox** на события со статусом `"new"`
2. **Публикация событий** в Kafka тему `outbox_events`
3. **Обновление статуса** на `"sent"` после успешной отправки
4. **Обработка ошибок** и повторные попытки отправки

## Паттерн Transactional Outbox — подробное объяснение

### Что такое Transactional Outbox

**Transactional Outbox** — это паттерн проектирования для обеспечения надёжной доставки событий в распределённых системах. Паттерн решает критическую проблему **двойной записи (double-write)** в распределённых системах, когда нужно атомарно обновить базу данных и отправить событие в message queue.

### Проблема без Outbox (Double-Write Problem)

В распределённых системах часто возникает необходимость:
1. Сохранить данные в базу данных
2. Отправить событие в message queue (Kafka, RabbitMQ и т.д.)

**Проблема**: Эти две операции не могут быть выполнены атомарно в разных системах.

**Сценарии сбоя**:
1. **Сервис упал после записи в БД, но до отправки в queue**:
   - Данные сохранены в БД ✅
   - Событие не отправлено в queue ❌
   - Результат: Данные есть, но обработка не началась

2. **Сервис упал после отправки в queue, но до коммита транзакции БД**:
   - Событие отправлено в queue ✅
   - Транзакция БД не закоммичена ❌
   - Результат: Обработка началась, но данных нет в БД

3. **Сеть недоступна при отправке в queue**:
   - Данные сохранены в БД ✅
   - Ошибка отправки в queue ❌
   - Результат: Данные есть, но событие потеряно

### Решение с Transactional Outbox

Паттерн решает проблему, разделяя операции на два этапа:

```
API Service → База данных (outbox таблица) [АТОМАРНАЯ ТРАНЗАКЦИЯ]
                    ↓
              Outbox Worker → Message Queue (асинхронная отправка)
```

**Принцип работы**:
1. **Атомарная запись**: API Service записывает данные в основную таблицу И в outbox таблицу в одной транзакции
2. **Асинхронная публикация**: Outbox worker забирает события и публикует в Kafka
3. **Гарантия доставки**: Событие не удаляется до успешной публикации в Kafka
4. **Отказоустойчивость**: При сбоях Kafka событие остаётся в outbox и будет обработано позже

### Преимущества паттерна

- **Надёжность**: События не теряются при сбоях Kafka или сети
- **Согласованность**: Транзакционная целостность данных (запись в БД и outbox атомарна)
- **Масштабируемость**: Можно запускать несколько worker'ов для параллельной обработки
- **Отказоустойчивость**: Автоматические повторные попытки при временных сбоях
- **Идемпотентность**: Повторная обработка безопасна (статус обновляется только после успеха)
- **Мониторинг**: Все события отслеживаются в БД, можно видеть статусы обработки
- **Разделение ответственности**: Основной сервис не зависит от доступности message queue

### Жизненный цикл события в Outbox

1. **Создание**: API Service создаёт событие в outbox со статусом `"new"` (атомарно с основной записью)
2. **Отправка**: Outbox Worker находит событие со статусом `"new"` и отправляет в Kafka
3. **Подтверждение**: После успешной отправки статус обновляется на `"sent"`
4. **Обработка**: Runner Service получает событие из Kafka и обрабатывает

## Архитектура

### Поток данных
```
api_checkout → MongoDB outbox → Outbox Worker → Kafka → Runner Service
```

### Статусы событий
- `new` — Событие создано, ожидает отправки
- `sent` — Событие успешно отправлено в Kafka

## Технические детали

### Зависимости
- **kafka-python** — синхронный клиент Kafka (используется синхронный клиент, так как worker работает в отдельном процессе)
- **pymongo** — клиент MongoDB
- **json** — сериализация сообщений

### Конфигурация
- **MongoDB**: `mongodb://admin:password@mongo:27017/`
- **Kafka**: `kafka:9092`
- **База данных**: `main_db`
- **Коллекция**: `outbox`
- **Kafka тема**: `outbox_events`

### Настройки Kafka Producer
```python
producer = KafkaProducer(
    bootstrap_servers=["kafka:9092"],
    value_serializer=lambda v: json.dumps(v).encode("utf-8"),
    key_serializer=lambda k: k.encode("utf-8") if k else None,  # Сериализация ключа
    retries=5,  # Повторные попытки отправки при временных сбоях
    # Идемпотентность на уровне producer
    enable_idempotence=True,  # Включает идемпотентность - предотвращает дубликаты сообщений
    max_in_flight_requests_per_connection=1,  # Требуется для идемпотентности (Kafka requirement)
    acks='all',  # Ждём подтверждения от всех реплик (требуется для идемпотентности)
)
```

**Зачем нужен идемпотентный producer?**

Идемпотентный producer решает критическую проблему атомарности между отправкой в Kafka и обновлением статуса в MongoDB:

**Проблема без идемпотентности:**
- Если `producer.send()` успешен, но `update_one()` упадёт (сеть, MongoDB недоступен)
- При следующей итерации событие отправится повторно → дубликат в Kafka

**Решение с идемпотентностью:**
- Kafka присваивает producer ID (PID) и sequence number каждому сообщению
- При повторной отправке брокер распознаёт дубликат по PID + sequence number и отклоняет его
- Сообщение не дублируется, даже если `update_one()` упадёт

**Message Key:**
- Используется `event_id` как ключ сообщения
- Гарантирует, что все сообщения с одним `event_id` попадут в одну partition
- Обеспечивает порядок обработки событий

### Почему используется синхронный клиент Kafka?

**Outbox Worker** работает как отдельный процесс (не в рамках FastAPI event loop), поэтому используется синхронный клиент `kafka-python` вместо асинхронного `aiokafka`:

- **Отдельный процесс**: Worker не использует asyncio event loop
- **Простота**: Синхронный код проще для worker'ов
- **Надёжность**: Kafka producer имеет встроенные retry механизмы
- **Производительность**: Для worker'а достаточно синхронного подхода

### Борьба с GIL и Event Loop

**Outbox Worker** работает как отдельный процесс, поэтому:
- **Не использует event loop**: Worker не является частью FastAPI приложения
- **GIL не критичен**: Worker выполняет I/O операции (MongoDB, Kafka), которые освобождают GIL
- **Простота**: Синхронный код проще для понимания и поддержки

**Примечание**: Если бы worker был частью FastAPI приложения, нужно было бы использовать `aiokafka` и `run_in_executor` для избежания блокировки event loop.

## Процесс обработки

### 1. Подключение к сервисам
```python
# Подключение к MongoDB
client = MongoClient("mongodb://admin:password@mongo:27017/")
db = client['main_db']
outbox = db['outbox']

# Подключение к Kafka с повторными попытками
while True:
    try:
        producer = KafkaProducer(...)
        break
    except Exception as e:
        time.sleep(5)
```

### 2. Основной цикл обработки
```python
while True:
    # Поиск новых событий
    events = list(outbox.find({"status": "new"}).limit(10))
    
    for event in events:
        # Формирование сообщения
        message = {
            "_id": str(event["_id"]),
            "payload": event["payload"],
            "created_at": str(event.get("created_at")),
        }
        
        # Отправка в Kafka
        producer.send("outbox_events", message)
        
        # Обновление статуса
        outbox.update_one(
            {"_id": event["_id"]},
            {"$set": {"status": "sent"}}
        )
    
    time.sleep(1)
```

## Формат сообщений

### Структура события в MongoDB
```json
{
  "_id": "video-uuid",
  "payload": {
    "bucket": "videos",
    "object": "input/video-uuid.mp4",
    "media_type": "video"
  },
  "created_at": "2024-01-01T12:00:00Z",
  "status": "new"
}
```

### Структура сообщения в Kafka
```json
{
  "_id": "video-uuid",
  "payload": {
    "bucket": "videos",
    "object": "input/video-uuid.mp4",
    "media_type": "video"
  },
  "created_at": "2024-01-01T12:00:00Z"
}
```

## Отказоустойчивость и проверка доступности сервисов

### Проверка доступности Kafka

Worker проверяет доступность Kafka при старте и автоматически восстанавливается при сбоях:

```python
# outbox/outbox_worker.py — подключение к Kafka с повторными попытками
# Ждём готовности Kafka
while True:
    try:
        producer = KafkaProducer(
            bootstrap_servers=["kafka:9092"],
            value_serializer=lambda v: json.dumps(v).encode("utf-8"),
            retries=5,  # Повторные попытки при ошибках
        )
        print("Connected to Kafka!")
        break  # Успешное подключение
    except Exception as e:
        print("Kafka not ready yet, retrying...", e)
        time.sleep(5)  # Повторная попытка через 5 секунд
```

**Преимущества**:
- **Автоматическое восстановление**: При восстановлении Kafka worker автоматически подключается
- **Не блокирует старт**: Worker запускается и ждёт доступности Kafka
- **Логирование**: Все ошибки подключения логируются

### Проверка доступности MongoDB

Worker обрабатывает ошибки MongoDB с логированием и продолжением работы:

```python
# outbox/outbox_worker.py — операции с MongoDB
# Подключаемся к MongoDB
client = MongoClient("mongodb://admin:password@mongo:27017/")
db = client['main_db']
outbox = db['outbox']

# Основной цикл обработки
while True:
    try:
        # Ищем события со статусом "new"
        events = list(outbox.find({"status": "new"}).limit(10))
        
        for event in events:
            try:
                # Отправка в Kafka...
                # Обновление статуса...
            except Exception as e:
                print(f"Failed to send to Kafka: {e}")
                # Событие остаётся со статусом "new" для повторной обработки
    except Exception as e:
        print(f"MongoDB error: {e}")
        # Продолжаем работу при временных сбоях MongoDB
    
    time.sleep(1)  # Проверяем каждую секунду
```

**Преимущества**:
- **Обработка ошибок**: Все ошибки MongoDB логируются
- **Продолжение работы**: Worker продолжает работать при временных сбоях БД
- **Повторная обработка**: События остаются в outbox для повторной обработки

## Обработка ошибок

### Типы ошибок и стратегия обработки

#### Ошибка подключения Kafka
- **Симптомы**: Не удаётся подключиться к Kafka брокеру
- **Обработка**: Повторные попытки каждые 5 секунд с логированием
- **Восстановление**: Автоматическое подключение при восстановлении Kafka

#### Ошибка отправки сообщения
- **Симптомы**: Не удаётся отправить сообщение в Kafka
- **Обработка**: Логирование ошибки, событие остаётся со статусом "new"
- **Восстановление**: Событие будет обработано при следующей итерации

#### Ошибка MongoDB
- **Симптомы**: Не удаётся прочитать/обновить данные в MongoDB
- **Обработка**: Логирование ошибки, продолжение работы
- **Восстановление**: Повторная попытка при следующей итерации

### Стратегия восстановления

1. **Kafka недоступен**: Worker продолжает попытки подключения каждые 5 секунд
2. **Ошибка отправки**: Событие остаётся в outbox со статусом "new" для повторной обработки
3. **MongoDB ошибка**: Логирование и продолжение работы, повторная попытка при следующей итерации
4. **Идемпотентность**: Повторная обработка безопасна (Kafka гарантирует доставку)

### Retry механизм Kafka Producer

Kafka producer имеет встроенный retry механизм:

```python
producer = KafkaProducer(
    bootstrap_servers=["kafka:9092"],
    value_serializer=lambda v: json.dumps(v).encode("utf-8"),
    retries=5,  # Автоматические повторные попытки при временных сбоях
)
```

**Преимущества**:
- **Автоматические повторы**: Producer автоматически повторяет отправку при временных сбоях
- **Надёжность**: Увеличивает вероятность успешной доставки
- **Прозрачность**: Не требует дополнительного кода для retry

## Производительность

### Оптимизации
- **Пакетная обработка**: До 10 событий за одну итерацию
- **Асинхронная отправка**: Использование Kafka producer batching
- **Опрос с интервалом**: 1 секунда между проверками

### Метрики
- **Пропускная способность**: Зависит от настроек Kafka
- **Задержка**: Минимальная (1 секунда)
- **Надёжность**: 99.9% (с retry механизмом)

## Логирование

Детальное логирование операций:
- Подключение к Kafka
- Найденные события
- Отправленные сообщения
- Ошибки и исключения

## Развертывание

### Docker конфигурация
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY outbox_worker.py .
CMD python outbox_worker.py
```

### Масштабирование
- Можно запускать несколько экземпляров worker'а
- MongoDB обеспечивает консистентность через атомарные операции
- Kafka обеспечивает порядок сообщений в рамках partition

## Важные замечания

1. **Идемпотентность**: Повторная обработка событий безопасна
2. **Порядок сообщений**: Kafka гарантирует порядок в рамках partition
3. **Отказоустойчивость**: Автоматическое восстановление после сбоев
4. **Мониторинг**: Логирование всех операций для отладки

## Исправления и улучшения

### Исправление проблем атомарности и идемпотентности (2024)

**Проблемы, которые были исправлены:**

1. **Отсутствие идемпотентности**: При повторной обработке события со статусом "new" оно могло быть отправлено в Kafka повторно, создавая дубликаты сообщений.

2. **Race condition**: При параллельной работе нескольких экземпляров воркера одно и то же событие могло быть обработано одновременно, что приводило к дублированию сообщений в Kafka.

3. **Отсутствие подтверждения отправки**: `producer.send()` возвращает Future, но код не ждал подтверждения отправки перед обновлением статуса. Если отправка не удалась, статус всё равно обновлялся.

4. **Нет защиты от изменения статуса**: Обновление статуса не проверяло, что статус всё ещё "new", что могло привести к обновлению уже обработанных событий.

5. **Проблема атомарности между Kafka и MongoDB**: Если `producer.send()` успешен, но `update_one()` упадёт (сеть, MongoDB недоступен), при следующей итерации событие отправится повторно, создавая дубликат в Kafka.

**Внесённые исправления:**

1. **Проверка статуса перед обработкой**: Перед обработкой события проверяется, что его статус всё ещё "new". Если статус изменился (обработан другим воркером), событие пропускается.

2. **Ожидание подтверждения отправки**: Добавлен `future.get(timeout=10)` для ожидания подтверждения успешной отправки сообщения в Kafka перед обновлением статуса.

3. **Условное обновление статуса**: Обновление статуса выполняется только если текущий статус равен "new" (`{"_id": event["_id"], "status": "new"}`). Это обеспечивает идемпотентность и защиту от race condition.

4. **Проверка результата обновления**: После обновления проверяется `result.modified_count` для определения, было ли обновление успешным или событие уже было обработано.

5. **Идемпотентный Kafka Producer**: Добавлен идемпотентный producer с параметрами:
   - `enable_idempotence=True` — включает идемпотентность на уровне producer
   - `max_in_flight_requests_per_connection=1` — требуется для идемпотентности
   - `acks='all'` — ждём подтверждения от всех реплик
   - `key=event_id` — используем event_id как ключ сообщения для партиционирования
   
   **Зачем это нужно:**
   - Kafka присваивает producer ID (PID) и sequence number каждому сообщению
   - При повторной отправке (если `update_one()` упадёт после успешной отправки) брокер распознаёт дубликат по PID + sequence number и отклоняет его
   - Это полностью решает проблему атомарности между Kafka и MongoDB — даже если `update_one()` упадёт, сообщение не будет дублировано в Kafka

**Цель исправлений:**

- **Идемпотентность**: Гарантировать, что повторная обработка события не создаст дубликаты в Kafka
- **Защита от race condition**: Предотвратить параллельную обработку одного события несколькими воркерами
- **Надёжность**: Обеспечить, что статус обновляется только после успешной отправки в Kafka
- **Масштабируемость**: Позволить безопасно запускать несколько экземпляров воркера для параллельной обработки

**Пример исправленного кода:**

```python
# Идемпотентный producer
producer = KafkaProducer(
    bootstrap_servers=["kafka:9092"],
    value_serializer=lambda v: json.dumps(v).encode("utf-8"),
    key_serializer=lambda k: k.encode("utf-8") if k else None,
    enable_idempotence=True,  # Идемпотентность
    max_in_flight_requests_per_connection=1,
    acks='all',
)

# Проверка статуса перед обработкой
current = outbox.find_one({"_id": event["_id"]})
if not current or current.get("status") != "new":
    continue  # Уже обработано другим воркером

# Отправка с message key для идемпотентности
event_id_str = str(event["_id"])
future = producer.send(
    "outbox_events",
    value=message,
    key=event_id_str  # Ключ для партиционирования и идемпотентности
)
future.get(timeout=10)  # Ждём подтверждения

# Условное обновление статуса (идемпотентность)
result = outbox.update_one(
    {"_id": event["_id"], "status": "new"},  # Условие
    {"$set": {"status": "sent"}}
)

if result.modified_count == 0:
    print("Event was already processed")
```

**Результат исправлений:**

- ✅ **Полная идемпотентность**: Даже если `update_one()` упадёт после успешной отправки, Kafka отклонит дубликат
- ✅ **Защита от race condition**: Условное обновление предотвращает параллельную обработку
- ✅ **Надёжность**: Статус обновляется только после подтверждения отправки
- ✅ **Масштабируемость**: Можно безопасно запускать несколько экземпляров воркера
